{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.readers.youtube_transcript import YoutubeTranscriptReader\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from youtube_transcript_api._errors import CouldNotRetrieveTranscript\n",
    "import urllib.request\n",
    "import re, os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from llama_index.embeddings.ollama import OllamaEmbedding\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.llms import ChatMessage\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = Ollama(\n",
    "    model=\"mistral\", \n",
    "    request_timeout=60.0\n",
    ")\n",
    "\n",
    "local_embed_model = OllamaEmbedding(\n",
    "    model_name=\"mxbai-embed-large\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    ollama_additional_kwargs={\"mirostat\": 0},\n",
    ")\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    engine = \"gpt-35-turbo\",\n",
    "    model = \"gpt-35-turbo\",\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'),  \n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    ")\n",
    "\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model = \"text-embedding-3-large\",\n",
    "    deployment_name = \"text-embedding-3-large\",\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'),\n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_youtube_videos(search_keyword: str) -> list:\n",
    "    html = urllib.request.urlopen(\"https://www.youtube.com/results?search_query=\" + search_keyword.replace(' ','+'))\n",
    "    video_ids = re.findall(r\"watch\\?v=(\\S{11})\", html.read().decode())\n",
    "    unique_ids = []\n",
    "    for id in video_ids:\n",
    "        if len(unique_ids) == 10:\n",
    "            break\n",
    "\n",
    "        if id not in unique_ids:\n",
    "            try:\n",
    "                YouTubeTranscriptApi.get_transcript(id)\n",
    "                unique_ids.append(id)\n",
    "            except CouldNotRetrieveTranscript:\n",
    "                pass\n",
    "            \n",
    "    return [\"https://www.youtube.com/watch?v=\"+i for i in unique_ids]\n",
    "\n",
    "get_youtube_videos_tool = FunctionTool.from_defaults(\n",
    "    fn=get_youtube_videos,\n",
    "    description=\"Returns list of 10 youtube video links for given search keyword.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_search_agent = ReActAgent.from_tools(\n",
    "    tools=[get_youtube_videos_tool],\n",
    "    llm=llm,\n",
    "    verbose=False,\n",
    "    context=\"Purpose: The primary role of this agent is to provide youtube video links for given query. Provide full link in answer.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "response1 = youtube_search_agent.query(\"Can you give me 10 videos for Samsung Galaxy S24 Ultra Review?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the 10 YouTube video links for the Samsung Galaxy S24 Ultra Review:\n",
      "1. https://www.youtube.com/watch?v=XaqOejIaFgM\n",
      "2. https://www.youtube.com/watch?v=z598clQ71JY\n",
      "3. https://www.youtube.com/watch?v=HvoBci_GC8A\n",
      "4. https://www.youtube.com/watch?v=K-JGaqfIOmI\n",
      "5. https://www.youtube.com/watch?v=2CvO99eGMLk\n",
      "6. https://www.youtube.com/watch?v=mEBbk38ENDA\n",
      "7. https://www.youtube.com/watch?v=dFpNqg5F2qQ\n",
      "8. https://www.youtube.com/watch?v=PNybdmok7m8\n",
      "9. https://www.youtube.com/watch?v=B4zSHZll8Gk\n",
      "10. https://www.youtube.com/watch?v=IA62EZx_HFE\n"
     ]
    }
   ],
   "source": [
    "print(response1.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_text(text: str) -> str:\n",
    "    prompt = f\"Summarize the following text in a concise way:\\n\\n{text}\"\n",
    "    \n",
    "    response = local_llm.chat([\n",
    "        ChatMessage(role=\"user\",content=prompt)\n",
    "    ])\n",
    "    \n",
    "    return response.message.content\n",
    "\n",
    "def youtube_links_to_summary(youtube_links: List[str]) -> bool:\n",
    "    loader = YoutubeTranscriptReader()\n",
    "    documents = loader.load_data(ytlinks=youtube_links)\n",
    "    df = pd.DataFrame([{'doc_id':doc.doc_id,'text':summarize_text(doc.text)} for doc in documents])\n",
    "    df.to_csv(\"top_10_summaries.csv\",index=False, sep=\"|\")\n",
    "    return True\n",
    "\n",
    "# def youtube_links_to_summary(youtube_links: List[str]) -> List[str]:\n",
    "#     loader = YoutubeTranscriptReader()\n",
    "#     documents = loader.load_data(ytlinks=youtube_links)\n",
    "#     df = pd.DataFrame([{'doc_id':doc.doc_id,'text':summarize_text(doc.text)} for doc in documents])\n",
    "#     df.to_csv(\"top_10_summaries.csv\",index=False, sep=\"|\")\n",
    "#     return df.text.to_list()\n",
    "\n",
    "summarize_youtube_video_tool = FunctionTool.from_defaults(\n",
    "    fn=youtube_links_to_summary,\n",
    "    # description=\"Returns array of summaries of all youtube links.\"\n",
    "    description=\"Returns True if summaries are stored in file.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_youtube_agent = ReActAgent.from_tools(\n",
    "    tools=[summarize_youtube_video_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    # context=\"Purpose: The primary role of this agent is to give summary of each youtube video link given in input.\"\n",
    "    context=\"Purpose: The primary role of this agent is to save summary of each youtube video link in csv file.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step abb74110-5377-46c3-9aa4-aa20b33b4a30. Step input: Give summary for each youtube links given here: Here are the 10 YouTube video links for the Samsung Galaxy S24 Ultra Review:\n",
      "1. https://www.youtube.com/watch?v=XaqOejIaFgM\n",
      "2. https://www.youtube.com/watch?v=z598clQ71JY\n",
      "3. https://www.youtube.com/watch?v=HvoBci_GC8A\n",
      "4. https://www.youtube.com/watch?v=K-JGaqfIOmI\n",
      "5. https://www.youtube.com/watch?v=2CvO99eGMLk\n",
      "6. https://www.youtube.com/watch?v=mEBbk38ENDA\n",
      "7. https://www.youtube.com/watch?v=dFpNqg5F2qQ\n",
      "8. https://www.youtube.com/watch?v=PNybdmok7m8\n",
      "9. https://www.youtube.com/watch?v=B4zSHZll8Gk\n",
      "10. https://www.youtube.com/watch?v=IA62EZx_HFE\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: youtube_links_to_summary\n",
      "Action Input: {'youtube_links': ['https://www.youtube.com/watch?v=XaqOejIaFgM', 'https://www.youtube.com/watch?v=z598clQ71JY', 'https://www.youtube.com/watch?v=HvoBci_GC8A', 'https://www.youtube.com/watch?v=K-JGaqfIOmI', 'https://www.youtube.com/watch?v=2CvO99eGMLk', 'https://www.youtube.com/watch?v=mEBbk38ENDA', 'https://www.youtube.com/watch?v=dFpNqg5F2qQ', 'https://www.youtube.com/watch?v=PNybdmok7m8', 'https://www.youtube.com/watch?v=B4zSHZll8Gk', 'https://www.youtube.com/watch?v=IA62EZx_HFE']}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [' In this video, the YouTuber reviews the new Samsung Galaxy S24 Ultra smartphone and its features. Some of the notable improvements include a new Voice Recorder app with improved speaker labels, summaries, transcriptions, a webpage summary feature in the Samsung Browser, and an updated Google Lens-like function called Circle to Search that allows users to quickly search images or objects on their screen by holding down the home button and circling the desired item. The video also mentions that the Pixel phones will soon have access to this Circle to Search feature as well. Additionally, Samsung has promised seven years of security updates and seven generations of major software updates for the S24 lineup. The video ends with the YouTuber discussing some of the similarities between the S24 Ultra and the iPhone 15 Pro Max, such as the titanium color option, boxier design, maximum 5X telephoto lens, always-on display, and object selection features. The video is sponsored by Ridge Wallet, a minimalist wallet with various colors and styles available.', \" Here is a summary of the features of the Samsung S24 Ultra that the reviewer found useful and not so useful:\\n\\nPositive features:\\n1. One UI: Adds polish to the Android experience with features like Modes, Routines, Sleep Mode, and the ability to customize the interface using the Good Lock app.\\n2. Multitasking: Allows easy switching between apps using the Edge Panel feature.\\n3. Seamless setup experience: Fast and easy data transfer from one Samsung phone to another without the need for a cable.\\n\\nNegative features or features not found useful:\\n1. Galaxy AI: Features like note summarization, message translation, live call translation are not important to the reviewer as they have other apps that meet their needs. The only feature they regularly use is Google's Circle to Search and Photo Assist.\\n2. Default keyboard: Found it does not correct as many typing mistakes as Gboard.\\n3. S Pen: While versatile, the reviewer found little use for it and prefers a lighter phone with the same camera system.\\n4. Heavy and bulky design: The phone is heavy and bulky to hold in one's hand for long periods of time.\\n5. Odd quirks with One UI: Custom lock screen player does not switch to showing skip buttons like Google's stock Android, and Good Lock no longer allows setting the app drawer to vertically scroll.\\n6. Battery replacement: The battery is not easily replaceable by the average user.\\n7. Limited use case for some features: The camera system may not be a significant upgrade if one already has a phone with decent camera capabilities. The reviewer suggests investing in a dedicated camera instead of upgrading to a new smartphone just for the camera.\", \" In summary, the user is reviewing the Samsung S24 smartphone, praising its performance but expressing concerns about some issues. They appreciate the AI features, despite them being based on Google tech and potentially becoming free for all phones in the future. They also dislike the fact that certain AI features require online servers and will only be free until 2025, which may result in additional subscription fees. The user notes that the phone has excellent battery life and is powerful enough to run demanding tasks like emulating PS2 games in HD. However, they express concern about thermal issues during prolonged stress tests. Overall, the user finds the S24 to be one of the top three smartphones in the market but suggests that phone companies should focus on creating reasons for their phones' power, such as working with game developers to bring popular games to mobile platforms. The review ends with a promotion for Surfshark VPN.\", \" The Samsung Galaxy S24 Ultra is an improved version of last year's flagship, offering a new 5x zoom camera, a brighter and flatter screen, and a revamped design. Key features include a QHD AMOLED screen with a 120 Hz refresh rate, support for HDR 10 plus video content, a Snapdragon 8 Gen 3 chipset, up to 1 TB of storage, and improved software AI-based features. The camera system consists of a 200 MP main cam, a 10 MP 3x zoom, a 12 MP ultra wide, and a new 50 MP 5x zoom camera. The phone has IP68 rated dust and water resistance, a pair of stereo speakers with good loudness, and supports wireless charging and reverse wireless charging. Software support is extended to 7 years. The battery capacity remains the same at 5,000 mAh.\", \" The Samsung Galaxy S24 Ultra has been used for six months, performing well in terms of battery life, camera quality, and durability. However, despite being a high-end Android phone with excellent features like a 6.8-inch LTPO AMOLED display, multiple cameras, and long update support, some users find it somewhat underwhelming compared to previous generations. The S24 Ultra's design, particularly its boxy corners, might cause slight discomfort during extended use. Camera performance is generally good, with the main lens producing accurate images that require minimal editing. However, low-light situations and ultra-wide shots may suffer some detail loss. Video stabilization has improved significantly this year. The included S Pen and AI features have not been extensively used by the reviewer, who finds them unnecessary for daily use. The software, One UI, is enjoyable to use with minimal lag. Battery life is impressive, lasting a full day even during heavy usage. Despite being one of the best Android phones in 2024, the S24 Ultra might not be as exciting as anticipated due to minor improvements from its predecessor. If you want the S24 Ultra's features but at a lower price, consider the S23 Ultra instead.\", ' The Galaxy S24 Ultra, released by Samsung, emphasizes software over hardware this year, introducing a new set of features powered by Generative AI. These AI-powered tools create content based on user prompts, such as generative edit for photo manipulation and language translation natively in the keyboard and phone app. However, similar features are available across all S24 phones, making it less compelling to upgrade, especially since these features will also be coming to the S23 series. Other new features include a Snapdragon 8 Gen 3 processor, a brighter screen, and a 50-megapixel telephoto camera offering crisper shots at a 5x Zoom. The reviewer found the language translation feature particularly useful, while noting that some AI features need improvement or are not exclusive to the Ultra model.', ' This text appears to be a review of various phone cases and phones themselves, with a focus on the Samsung Galaxy S24 Ultra 5G. The author expresses their love for a specific Mouse case called \"super thin\" with MagSafe, and mentions having other cases for the Pixel and the Galaxy S24. They also mention a carbon fiber case for the Galaxy S24.\\n\\nThe author introduces a concept they call the \"floss Factor,\" which is a hypothetical situation where various phone models are on a table, and the owner of the Galaxy S24 Ultra 5G is considered the supreme boss. They go on to discuss the features and capabilities of the Galaxy S24 Ultra 5G, emphasizing its versatility and unique functions compared to other phones.\\n\\nThe author then switches to a more personal note, discussing their friendship with someone named Moo, who was an \"Apple Mafia\" member, and how they had a friendly bet about the Galaxy S24\\'s release. Moo passed away in September, and when the Xiaomi 14 Pro came out in titanium, the author realized that Android had indeed copied Apple\\'s design faster than expected, fulfilling Moo\\'s prediction.\\n\\nThe author ends the review by encouraging viewers to squash their petty differences with friends and family, as one never knows when they might be gone. They also encourage viewers to upgrade their phones if it is a hobby they enjoy, as life is not promised. The author then concludes by thanking their followers on various social media platforms and inviting them to join their streams on Sundays.', \" Based on your review, it seems like you have a mixed opinion about the Samsung Galaxy S24 Ultra. On one hand, you appreciate its impressive detail capture capabilities, depth of field, and unique AI features such as Circle to Search, Photo Assist, and Slow Motion. However, you criticize some aspects like aggressive post-processing, dynamic range struggles in certain scenarios, and unnecessary pre-installed apps. You also suggest simplifying the camera app layout for a smoother user experience.\\n\\nRegarding software, you praise One UI's Quick Settings tray, photo management system, and AI-powered features like live Translate and Interpreter. However, you express concerns about AI intrusiveness, the need to create a Samsung account to use certain features, and bugs in Samsung Dex, especially with the YouTube player.\\n\\nIn conclusion, the Samsung Galaxy S24 Ultra showcases impressive hardware and AI capabilities but requires improvements in areas such as post-processing, dynamic range, software polish, and affordability. It's a testament to the state of smartphone technology today, where incremental updates are common, and consumers have high expectations for price, performance, and user experience.\", \" The author has been using the Samsung Galaxy S24 Ultra for four months and while they find it an overall treat, there are minor issues. However, these concerns aren't enough to deter them from recommending it if someone is new to Android. The phone's large 6.8-inch display with a 2600 nit peak brightness and anti-glare coating make it stand out, especially in outdoor conditions. The Snapdragon 8 Gen 3 chipset has been a powerhouse for both performance in mobile games and daily tasks. Despite some reported issues like a grainy display when viewing gray or dark backgrounds, the author doesn't personally notice this problem. They appreciate the new five-times telephoto camera and design of the phone. The only drawbacks mentioned are the high price compared to other devices, compatibility issues with non-Android users in group chats, and a recent battery life concern that might be resolved through software updates. Overall, they highly recommend the Samsung Galaxy S24 Ultra.\", \" The text is about the Samsung Galaxy S24 Ultra, which has been the best-selling Android phone worldwide. The author praises its design and durability, citing their personal experience of using it without a case. They also discuss the Galaxy Ai feature now available on older Samsung flagships due to a recent update. They suggest that one can save money by opting for the S23 Ultra instead of the S24 Ultra if they want access to this feature. The author praises the phone's display, battery life, software experience, and camera performance. However, they note that video performance in low light scenarios needs improvement. They also mention Samsung's promise of providing 7 years of major OS updates for the S24 Ultra.\"]\n",
      "\u001b[0m> Running step b8dd1935-6448-4c5e-9e42-cdbaf8e762c1. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Based on the summaries of the YouTube video links for the Samsung Galaxy S24 Ultra, it seems that the reviewers have highlighted various aspects of the phone, including its features, performance, and drawbacks. The reviews cover details such as the new features of the S24 Ultra, the positive and negative aspects of the phone, comparisons with previous models, and recommendations for potential buyers. Overall, the reviews provide a comprehensive overview of the Samsung Galaxy S24 Ultra, offering insights into its strengths and weaknesses.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# response2 = summarize_youtube_agent.query(\"Save summary for each youtube links given here: \"+response1.response)\n",
    "response2 = summarize_youtube_agent.query(\"Give summary for each youtube links given here: \"+response1.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the summaries of the YouTube video links for the Samsung Galaxy S24 Ultra, it seems that the reviewers have highlighted various aspects of the phone, including its features, performance, and drawbacks. The reviews cover details such as the new features of the S24 Ultra, the positive and negative aspects of the phone, comparisons with previous models, and recommendations for potential buyers. Overall, the reviews provide a comprehensive overview of the Samsung Galaxy S24 Ultra, offering insights into its strengths and weaknesses.\n"
     ]
    }
   ],
   "source": [
    "print(response2.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    vec1 = np.array(vec1)\n",
    "    vec2 = np.array(vec2)\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    norm_vec1 = np.linalg.norm(vec1)\n",
    "    norm_vec2 = np.linalg.norm(vec2)\n",
    "    return dot_product / (norm_vec1 * norm_vec2)\n",
    "\n",
    "def get_top_n_similar_videos(top_n: int) -> List[dict]:\n",
    "    df = pd.read_csv(\"top_10_summaries.csv\",sep=\"|\")\n",
    "    documents = []\n",
    "    for t in df.itertuples():\n",
    "        documents.append(\n",
    "            Document(\n",
    "                doc_id=t.doc_id,\n",
    "                text=t.text,\n",
    "                metadata={'video_id':t.doc_id},\n",
    "                embedding=local_embed_model.get_text_embedding(t.text)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    sim_matrix = np.zeros(shape=(10,10))\n",
    "    for i in range(len(documents)):\n",
    "        for j in range(i+1,len(documents)):\n",
    "            sim_matrix[i][j] = cosine_similarity(documents[i].embedding,documents[j].embedding)\n",
    "    \n",
    "    flat_sim_matrix = sim_matrix.flatten()\n",
    "    indices = np.argpartition(flat_sim_matrix, -top_n)[-top_n:]\n",
    "    indices = np.flip(indices[np.argsort(flat_sim_matrix[indices])])\n",
    "\n",
    "    most_similar_pairs = []\n",
    "    for idx in indices:\n",
    "        max_idx = np.unravel_index(idx,sim_matrix.shape)\n",
    "        most_similar_pairs.append({\n",
    "            'video1': \"https://www.youtube.com/watch?v=\"+documents[max_idx[0]].doc_id,\n",
    "            'video2': \"https://www.youtube.com/watch?v=\"+documents[max_idx[1]].doc_id,\n",
    "            'similarity': sim_matrix[max_idx[0]][max_idx[1]]\n",
    "        })\n",
    "    \n",
    "    return most_similar_pairs\n",
    "\n",
    "most_similar_videos_tool = FunctionTool.from_defaults(\n",
    "    fn=get_top_n_similar_videos,\n",
    "    description=\"Returns list of pairs of youtube links with most similarity.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_agent = ReActAgent.from_tools(\n",
    "    tools=[most_similar_videos_tool],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    context=\"Purpose: The primary role of this agent is to give n pairs of most similar youtube videos.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 67300996-2c83-4cb7-aaf5-11a99daf9c74. Step input: Give me 3 pairs of most similar videos.\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: get_top_n_similar_videos\n",
      "Action Input: {'top_n': 3}\n",
      "\u001b[0m\u001b[1;3;34mObservation: [{'video1': 'https://www.youtube.com/watch?v=5_yMa3hzCLs', 'video2': 'https://www.youtube.com/watch?v=2CvO99eGMLk', 'similarity': 0.8210053485068398}, {'video1': 'https://www.youtube.com/watch?v=2CvO99eGMLk', 'video2': 'https://www.youtube.com/watch?v=IA62EZx_HFE', 'similarity': 0.8170498501258571}, {'video1': 'https://www.youtube.com/watch?v=K-JGaqfIOmI', 'video2': 'https://www.youtube.com/watch?v=5_yMa3hzCLs', 'similarity': 0.812141434787413}]\n",
      "\u001b[0m> Running step ab119c0a-dd4b-4eb3-b23a-18600e8b1f05. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: Here are the 3 pairs of most similar videos:\n",
      "1. Pair 1: \n",
      "   - Video 1: [https://www.youtube.com/watch?v=5_yMa3hzCLs](https://www.youtube.com/watch?v=5_yMa3hzCLs)\n",
      "   - Video 2: [https://www.youtube.com/watch?v=2CvO99eGMLk](https://www.youtube.com/watch?v=2CvO99eGMLk)\n",
      "   - Similarity: 0.821\n",
      "\n",
      "2. Pair 2:\n",
      "   - Video 1: [https://www.youtube.com/watch?v=2CvO99eGMLk](https://www.youtube.com/watch?v=2CvO99eGMLk)\n",
      "   - Video 2: [https://www.youtube.com/watch?v=IA62EZx_HFE](https://www.youtube.com/watch?v=IA62EZx_HFE)\n",
      "   - Similarity: 0.817\n",
      "\n",
      "3. Pair 3:\n",
      "   - Video 1: [https://www.youtube.com/watch?v=K-JGaqfIOmI](https://www.youtube.com/watch?v=K-JGaqfIOmI)\n",
      "   - Video 2: [https://www.youtube.com/watch?v=5_yMa3hzCLs](https://www.youtube.com/watch?v=5_yMa3hzCLs)\n",
      "   - Similarity: 0.812\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response3 = similarity_agent.query(\"Give me 3 pairs of most similar videos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from factory import youtube_search_agent_factory, summarize_youtube_agent_factory, similarity_agent_factory\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    engine = \"gpt-35-turbo\",\n",
    "    model = \"gpt-35-turbo\",\n",
    "    api_key = os.getenv('AZURE_OPENAI_API_KEY'),  \n",
    "    api_version = \"2024-02-01\",\n",
    "    azure_endpoint = os.getenv('AZURE_OPENAI_ENDPOINT')\n",
    ")\n",
    "\n",
    "orchestrator = ReActAgent.from_tools(\n",
    "    tools=[youtube_search_agent_factory, summarize_youtube_agent_factory, similarity_agent_factory],\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    context=\"You are on orchestration agent. Your job is to decide which agent to run based on the current state of the user and what they've asked to do. Agents are identified by tools.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 81bf059a-e606-4883-8656-a3e538d06e03. Step input: Find 3 pairs most similar videos for Iphone 16 pro max review.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'metadata'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43morchestrator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFind 3 pairs most similar videos for Iphone 16 pro max review.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\base\\base_query_engine.py:52\u001b[0m, in \u001b[0;36mBaseQueryEngine.query\u001b[1;34m(self, str_or_query_bundle)\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(str_or_query_bundle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m     51\u001b[0m         str_or_query_bundle \u001b[38;5;241m=\u001b[39m QueryBundle(str_or_query_bundle)\n\u001b[1;32m---> 52\u001b[0m     query_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstr_or_query_bundle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m     54\u001b[0m     QueryEndEvent(query\u001b[38;5;241m=\u001b[39mstr_or_query_bundle, response\u001b[38;5;241m=\u001b[39mquery_result)\n\u001b[0;32m     55\u001b[0m )\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m query_result\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\callbacks\\utils.py:41\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\base\\agent\\types.py:49\u001b[0m, in \u001b[0;36mBaseAgent._query\u001b[1;34m(self, query_bundle)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_query\u001b[39m(\u001b[38;5;28mself\u001b[39m, query_bundle: QueryBundle) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m RESPONSE_TYPE:\n\u001b[1;32m---> 49\u001b[0m     agent_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_bundle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_str\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Response(\n\u001b[0;32m     54\u001b[0m         response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m(agent_response), source_nodes\u001b[38;5;241m=\u001b[39magent_response\u001b[38;5;241m.\u001b[39msource_nodes\n\u001b[0;32m     55\u001b[0m     )\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\callbacks\\utils.py:41\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\runner\\base.py:647\u001b[0m, in \u001b[0;36mAgentRunner.chat\u001b[1;34m(self, message, chat_history, tool_choice)\u001b[0m\n\u001b[0;32m    642\u001b[0m     tool_choice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_tool_choice\n\u001b[0;32m    643\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_manager\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    644\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mAGENT_STEP,\n\u001b[0;32m    645\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mMESSAGES: [message]},\n\u001b[0;32m    646\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 647\u001b[0m     chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_chat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    648\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    649\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchat_history\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    650\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    651\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatResponseMode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWAIT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    652\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    653\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chat_response, AgentChatResponse)\n\u001b[0;32m    654\u001b[0m     e\u001b[38;5;241m.\u001b[39mon_end(payload\u001b[38;5;241m=\u001b[39m{EventPayload\u001b[38;5;241m.\u001b[39mRESPONSE: chat_response})\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\runner\\base.py:579\u001b[0m, in \u001b[0;36mAgentRunner._chat\u001b[1;34m(self, message, chat_history, tool_choice, mode)\u001b[0m\n\u001b[0;32m    576\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(AgentChatWithStepStartEvent(user_msg\u001b[38;5;241m=\u001b[39mmessage))\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;66;03m# pass step queue in as argument, assume step executor is stateless\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_choice\u001b[49m\n\u001b[0;32m    581\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m cur_step_output\u001b[38;5;241m.\u001b[39mis_last:\n\u001b[0;32m    584\u001b[0m         result_output \u001b[38;5;241m=\u001b[39m cur_step_output\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\runner\\base.py:412\u001b[0m, in \u001b[0;36mAgentRunner._run_step\u001b[1;34m(self, task_id, step, input, mode, **kwargs)\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[38;5;66;03m# TODO: figure out if you can dynamically swap in different step executors\u001b[39;00m\n\u001b[0;32m    409\u001b[0m \u001b[38;5;66;03m# not clear when you would do that by theoretically possible\u001b[39;00m\n\u001b[0;32m    411\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mWAIT:\n\u001b[1;32m--> 412\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_worker\u001b[38;5;241m.\u001b[39mrun_step(step, task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    413\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m ChatResponseMode\u001b[38;5;241m.\u001b[39mSTREAM:\n\u001b[0;32m    414\u001b[0m     cur_step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent_worker\u001b[38;5;241m.\u001b[39mstream_step(step, task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\instrumentation\\dispatcher.py:307\u001b[0m, in \u001b[0;36mDispatcher.span.<locals>.wrapper\u001b[1;34m(func, instance, args, kwargs)\u001b[0m\n\u001b[0;32m    304\u001b[0m             _logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to reset active_span_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    306\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 307\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    308\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, asyncio\u001b[38;5;241m.\u001b[39mFuture):\n\u001b[0;32m    309\u001b[0m         \u001b[38;5;66;03m# If the result is a Future, wrap it\u001b[39;00m\n\u001b[0;32m    310\u001b[0m         new_future \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(result)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\callbacks\\utils.py:41\u001b[0m, in \u001b[0;36mtrace_method.<locals>.decorator.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m callback_manager \u001b[38;5;241m=\u001b[39m cast(CallbackManager, callback_manager)\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m callback_manager\u001b[38;5;241m.\u001b[39mas_trace(trace_id):\n\u001b[1;32m---> 41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\react\\step.py:797\u001b[0m, in \u001b[0;36mReActAgentWorker.run_step\u001b[1;34m(self, step, task, **kwargs)\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[38;5;129m@trace_method\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_step\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    795\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, step: TaskStep, task: Task, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TaskStepOutput:\n\u001b[0;32m    796\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Run step.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 797\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\react\\step.py:562\u001b[0m, in \u001b[0;36mReActAgentWorker._run_step\u001b[1;34m(self, step, task)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[38;5;66;03m# TODO: see if we want to do step-based inputs\u001b[39;00m\n\u001b[0;32m    561\u001b[0m tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_tools(task\u001b[38;5;241m.\u001b[39minput)\n\u001b[1;32m--> 562\u001b[0m input_chat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_react_chat_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchat_history\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmemory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnew_memory\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcurrent_reasoning\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextra_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcurrent_reasoning\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;66;03m# send prompt\u001b[39;00m\n\u001b[0;32m    570\u001b[0m chat_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_llm\u001b[38;5;241m.\u001b[39mchat(input_chat)\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\react\\formatter.py:67\u001b[0m, in \u001b[0;36mReActChatFormatter.format\u001b[1;34m(self, tools, chat_history, current_reasoning)\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Format chat history into list of ChatMessage.\"\"\"\u001b[39;00m\n\u001b[0;32m     64\u001b[0m current_reasoning \u001b[38;5;241m=\u001b[39m current_reasoning \u001b[38;5;129;01mor\u001b[39;00m []\n\u001b[0;32m     66\u001b[0m format_args \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m---> 67\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_desc\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mget_react_tool_descriptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m),\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_names\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin([tool\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mget_name() \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools]),\n\u001b[0;32m     69\u001b[0m }\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext:\n\u001b[0;32m     71\u001b[0m     format_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\agent\\react\\formatter.py:27\u001b[0m, in \u001b[0;36mget_react_tool_descriptions\u001b[1;34m(tools)\u001b[0m\n\u001b[0;32m     24\u001b[0m tool_descs \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tool \u001b[38;5;129;01min\u001b[39;00m tools:\n\u001b[0;32m     26\u001b[0m     tool_desc \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m---> 27\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m> Tool Name: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mtool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     28\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool Description: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mdescription\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     29\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTool Args: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtool\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mfn_schema_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     30\u001b[0m     )\n\u001b[0;32m     31\u001b[0m     tool_descs\u001b[38;5;241m.\u001b[39mappend(tool_desc)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tool_descs\n",
      "File \u001b[1;32md:\\Projects\\Noha.ai\\.venv\\lib\\site-packages\\llama_index\\core\\tools\\types.py:192\u001b[0m, in \u001b[0;36mBaseToolAsyncAdapter.metadata\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmetadata\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ToolMetadata:\n\u001b[1;32m--> 192\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbase_tool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmetadata\u001b[49m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'function' object has no attribute 'metadata'"
     ]
    }
   ],
   "source": [
    "orchestrator.query(\"Find 3 pairs most similar videos for Iphone 16 pro max review.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
